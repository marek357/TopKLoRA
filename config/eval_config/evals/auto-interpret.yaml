name: auto-interpret

# ablation_study: False
# activations_study: True
# train_steps: 5000
# max_new_tokens: 125
# hook_type: "disable"
# max_examples_per_latent: 250
# latent_interp_batch_size: 10
# max_length: 512
# max_rows: 10
# context_size_each_side: 10
# dump_generated: True
# dump_analysis: True
# sleep_sec: 0.5
# chat_model: "gpt-4o"
# chat_model_temperature: 0.0
# chat_system_prompt: "You are a helpful assistant."

activation_collection:
  enabled: true
  n_tokens: 10000
  seq_len: 256
  top_prompt_count: 100
  max_batches: 500000
  batch_size: 8
  dataset_name: "Anthropic/hh-rlhf"
  dataset_split: train
  dataset_continuation: rejected # or "chosen" or "null" for randomly selected
  dataset_config_name: null

# selection of top latents to analyse
latent_selection:
  enabled: true
  max_latents: 128
  p_active_min: 0.01
  p_active_max: 0.8
  dead_p_active_max: 0.0099

seed: 42
build_eval_function:
  _target_: src.evals.auto_interp
